{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import cross_validation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random as ra\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "\n",
    "data = pd.DataFrame(boston.data) \n",
    "data.columns = boston.feature_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Price'] = boston.target \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  Price  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Price'], axis = 1)\n",
    "\n",
    "Y = data[['Price']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y= Y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = cross_validation.train_test_split(X,Y,test_size = 0.2)\n",
    "Y_train = Y_train.reshape(Y_train.shape[0],)\n",
    "Y_test = Y_test.reshape(Y_test.shape[0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(102, 13)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Y_test.shape)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialising W from a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.40303401  0.78394147  0.62801585  0.9283807   0.26390203  0.44945639\n",
      "  1.54358151  1.54525183 -0.18790266  0.92023526  0.14682882  0.92873559\n",
      " -0.36988331]\n"
     ]
    }
   ],
   "source": [
    "Wo = np.random.normal(0, 1, X_train.shape[1])\n",
    "Bo = ra.uniform(1,10)\n",
    "Lr =0.001\n",
    "#Wo = np.random.uniform(-1,1,X_train.shape[1])\n",
    "print(Wo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient w.r.t W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradienCalc(X,Y,W,B,N,Lr):\n",
    "    \n",
    "    loss =  Y - (np.dot(X,W)+B)\n",
    "\n",
    "    grad =  (2*(np.dot(loss,X))/N)*Lr\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient w.r.t B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradienCalcB(X,Y,W,B,N,Lr):\n",
    "    \n",
    "    loss =  Y - (np.dot(X,W)+B)\n",
    "\n",
    "    gradB = ((2*np.sum(loss))/N)*Lr\n",
    "    \n",
    "    return gradB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Squared Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossCalc(X,Y,W,B,N):\n",
    "    \n",
    "    Loss = np.sum((Y - ((np.dot(X,W))+B))**2)\n",
    "    \n",
    "    return Loss/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "batch = 30\n",
    "iterations = 100000\n",
    "\n",
    "test_Y = Y_train.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final Weight [-6.21632482e-01  9.46435134e-01  1.08197484e-03  1.07841418e+00\n",
      " -1.49881989e+00  3.18357165e+00 -2.26026374e-01 -2.64878125e+00\n",
      "  1.59525284e+00 -9.81386426e-01 -1.82403639e+00  8.28904004e-01\n",
      " -3.68945581e+00]\n",
      "Final iteration number  5001\n",
      "Loss after final iteration on Train data  23.032413752052666\n"
     ]
    }
   ],
   "source": [
    "for i in range(iterations):\n",
    "    \n",
    " \n",
    "    #=========================================================================================================================\n",
    "    # If iterations increase, convergence is not happening because of overshooting, so after 5000 iterations learning rate is decreased to 000001\n",
    "    \n",
    "    if i > 5000:\n",
    "        \n",
    "        Lr = 0.000001;\n",
    "    \n",
    "    #=================================================================================\n",
    "    \n",
    "    # Batch SGD with batch size 10\n",
    "    \n",
    "    end = start+batch\n",
    "    \n",
    "    if (start >= X_train.shape[0]):\n",
    "        \n",
    "        start = 0;\n",
    "        end   = batch;\n",
    "        \n",
    "    if (end > X_train.shape[0]):\n",
    "        \n",
    "        end = X_train.shape[0]\n",
    "        \n",
    "\n",
    "    mini_batch_X = X_train[start:end,:] \n",
    "        \n",
    "    mini_batch_Y = test_Y[start:end,:] \n",
    "\n",
    "    mini_batch_Y = mini_batch_Y.reshape((end-start),)\n",
    "        \n",
    "    \n",
    "  #================================================================================================      \n",
    "    \n",
    "    # Updating the Weights\n",
    "    \n",
    "    \n",
    "    grad = gradienCalc(mini_batch_X,mini_batch_Y,Wo,Bo,mini_batch_X.shape[0],Lr)\n",
    "    \n",
    "    gradB = gradienCalcB(mini_batch_X,mini_batch_Y,Wo,Bo,mini_batch_X.shape[0],Lr)\n",
    "  \n",
    "\n",
    "    Wn = Wo + grad\n",
    "    Bn = Bo + gradB\n",
    "    \n",
    "   #==============================================================================================\n",
    "\n",
    "    dist = np.linalg.norm(Wo-Wn)\n",
    "\n",
    "    if (dist < 0.00001 and abs(Bo-Bn)<0.00001):\n",
    "        \n",
    "        \n",
    "        print(\"final Weight\",Wo)\n",
    "        \n",
    "        print(\"Final iteration number \",i)\n",
    "        \n",
    "        print(\"Loss after final iteration on Train data \",lossCalc(X_train,Y_train,Wo,Bo,X_train.shape[0]))\n",
    "        \n",
    "        break;\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        Wo = Wn\n",
    "        Bo = Bn\n",
    "        \n",
    "        start = end+1\n",
    "\n",
    "    if i>=99999:\n",
    "\n",
    "        print(\"end of iterations\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.21632482e-01  9.46435134e-01  1.08197484e-03  1.07841418e+00\n",
      " -1.49881989e+00  3.18357165e+00 -2.26026374e-01 -2.64878125e+00\n",
      "  1.59525284e+00 -9.81386426e-01 -1.82403639e+00  8.28904004e-01\n",
      " -3.68945581e+00]\n",
      "22.47164145487635\n"
     ]
    }
   ],
   "source": [
    "print(Wo)\n",
    "print(Bo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Linear Regression For train data from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearRegression(fit_intercept=True, normalize=False)\n",
    "clf.fit(X_train, Y_train)\n",
    "predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Mean squared error loss for SGD with SKLEARN on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual SGD model loss  20.16044300155029\n",
      "sklearn regression loss 21.47884584994866\n"
     ]
    }
   ],
   "source": [
    "#========================================================\n",
    "\n",
    "# Mean squared loss on Manual SGD model\n",
    "\n",
    "finalLoss = lossCalc(X_test,Y_test,Wo,Bo,X_test.shape[0])\n",
    "\n",
    "#=====================================================\n",
    "\n",
    "# Mean squared loss on sklearn regression model\n",
    "\n",
    "LrLoss = mean_squared_error(Y_test, predicted)\n",
    "\n",
    "#=====================================================\n",
    "\n",
    "print(\"Manual SGD model loss \", finalLoss)\n",
    "print(\"sklearn regression loss\", LrLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                     SGD model    Sklearn model\n",
      "-----------------------  -----------  ---------------\n",
      "Final intercept              22.4716          22.6679\n",
      "Final loss on test data      20.1604          21.4788\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[\"Final intercept\",Bo,clf.intercept_ ], [\"Final loss on test data\", finalLoss,LrLoss]], headers=['Metric', 'SGD model','Sklearn model']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final weight after SGD  [-6.21632482e-01  9.46435134e-01  1.08197484e-03  1.07841418e+00\n",
      " -1.49881989e+00  3.18357165e+00 -2.26026374e-01 -2.64878125e+00\n",
      "  1.59525284e+00 -9.81386426e-01 -1.82403639e+00  8.28904004e-01\n",
      " -3.68945581e+00]\n",
      "Final weight for sklearn regression   [-1.02532654  1.25215932  0.18352221  0.78413397 -2.44434557  2.54620177\n",
      "  0.09540011 -3.65523423  2.7303766  -1.97145155 -2.15834563  0.8012498\n",
      " -4.00781444]\n"
     ]
    }
   ],
   "source": [
    "print(\"Final weight after SGD \", Wo)\n",
    "print(\"Final weight for sklearn regression  \", clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
